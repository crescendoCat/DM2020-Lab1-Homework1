{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Student Information\n",
    "Name:吳霽函\n",
    "\n",
    "Student ID:109065523\n",
    "\n",
    "GitHub ID:crescendoCat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. First: do the **take home** exercises in the [DM2020-Lab1-Master Repo](https://github.com/fhcalderon87/DM2020-Lab1-Master). You may need to copy some cells from the Lab notebook to this notebook. __This part is worth 20% of your grade.__\n",
    "\n",
    "\n",
    "2. Second: follow the same process from the [DM2020-Lab1-Master Repo](https://github.com/fhcalderon87/DM2020-Lab1-Master) on **the new dataset**. You don't need to explain all details as we did (some **minimal comments** explaining your code are useful though).  __This part is worth 30% of your grade.__\n",
    "    - Download the [the new dataset](https://archive.ics.uci.edu/ml/datasets/Sentiment+Labelled+Sentences#). The dataset contains a `sentence` and `score` label. Read the specificiations of the dataset for details. \n",
    "    - You are allowed to use and modify the `helper` functions in the folder of the first lab session (notice they may need modification) or create your own.\n",
    "\n",
    "\n",
    "3. Third: please attempt the following tasks on **the new dataset**. __This part is worth 30% of your grade.__\n",
    "    - Generate meaningful **new data visualizations**. Refer to online resources and the Data Mining textbook for inspiration and ideas. \n",
    "    - Generate **TF-IDF features** from the tokens of each text. This will generating a document matrix, however, the weights will be computed differently (using the TF-IDF value of each word per document as opposed to the word frequency). Refer to this Sciki-learn [guide](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html) .\n",
    "    - Implement a simple **Naive Bayes classifier** that automatically classifies the records into their categories. Use both the TF-IDF features and word frequency features to build two seperate classifiers. Comment on the differences.  Refer to this [article](https://hub.packtpub.com/implementing-3-naive-bayes-classifiers-in-scikit-learn/).\n",
    "\n",
    "\n",
    "4. Fourth: In the lab, we applied each step really quickly just to illustrate how to work with your dataset. There are somethings that are not ideal or the most efficient/meaningful. Each dataset can be habdled differently as well. What are those inefficent parts you noticed? How can you improve the Data preprocessing for these specific datasets? __This part is worth 10% of your grade.__\n",
    "\n",
    "\n",
    "5. Fifth: It's hard for us to follow if your code is messy :'(, so please **tidy up your notebook** and **add minimal comments where needed**. __This part is worth 10% of your grade.__\n",
    "\n",
    "\n",
    "You can submit your homework following these guidelines: [Git Intro & How to hand your homework](https://github.com/fhcalderon87/DM2020-Lab1-Master/blob/master/Git%20Intro%20%26%20How%20to%20hand%20your%20homework.ipynb). Make sure to commit and save your changes to your repository __BEFORE the deadline (Oct. 22th 11:59 pm, Thursday)__. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Take Home Exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# TEST necessary for when working with external scripts\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation\n",
    "Preparing the data for __Take Home Exercises__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "import pandas as pd\n",
    "# PA's useful functions\n",
    "import helpers.data_mining_helpers as dmh\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categories\n",
    "categories = ['alt.atheism', 'soc.religion.christian', 'comp.graphics', 'sci.med']\n",
    "\n",
    "twenty_train = fetch_20newsgroups(subset='train', categories=categories, \\\n",
    "                                  shuffle=True, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "# construct dataframe from a list\n",
    "X = pd.DataFrame.from_records(dmh.format_rows(twenty_train), columns= ['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['category'] = twenty_train.target\n",
    "X['category_name'] = X.category.apply(lambda t: dmh.format_labels(t, twenty_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### >>>  **Exercise 2 (take home):** \n",
    "Experiment with other querying techniques using pandas dataframes. Refer to their [documentation](https://pandas.pydata.org/pandas-docs/stable/indexing.html) for more information. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### My Answer ###\n",
    "The following cells, I try to figure out the number of the row which text's lenght is over 700.\\\n",
    "And I try drawing a bar plot to visualize this thing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "vlen = np.vectorize(len)\n",
    "# vectorize python len function to compute each text's length in the data\n",
    "print(vlen(X['text']))\n",
    "# Select those text length > 700, pick the category column only\n",
    "X.loc[vlen(X['text']) > 700, 'category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bins = [-0.5, 0.5, 1.5, 2.5, 3.5]\n",
    "\n",
    "# Compute the histogram. Classify the data using category\n",
    "hist = np.histogram(X.loc[vlen(X['text']) > 700, 'category'], bins=bins)\n",
    "plt.bar([0, 1, 2, 3], hist[0], width=0.3)\n",
    "plt.xticks([0, 1, 2, 3])\n",
    "plt.xlabel('category')\n",
    "plt.ylabel('text number > 700')\n",
    "plt.title('Graph')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also we can set different threshold on text length to see a rough distribution of text length in the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = [-0.5, 0.5, 1.5, 2.5, 3.5]\n",
    "xtick = np.array([0, 1, 2, 3])\n",
    "\n",
    "for threshold, pos in zip([300, 700, 1200, 2000], [-0.3, -0.1, 0.1, 0.3]):\n",
    "    hist = np.histogram(X.loc[vlen(X['text']) > threshold, 'category'], bins=bins)\n",
    "    plt.bar(xtick + pos, hist[0], width=0.2) \n",
    "plt.xticks([0, 1, 2, 3])\n",
    "plt.xlabel('category')\n",
    "plt.ylabel('text number > 700')\n",
    "plt.title('Graph')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### >>> **Exercise 5 (take home)** \n",
    "There is an old saying that goes, \"The devil is in the details.\" When we are working with extremely large data, it's difficult to check records one by one (as we have been doing so far). And also, we don't even know what kind of missing values we are facing. Thus, \"debugging\" skills get sharper as we spend more time solving bugs. Let's focus on a different method to check for missing values and the kinds of missing values you may encounter. It's not easy to check for missing values as you will find out in a minute.\n",
    "\n",
    "Please check the data and the process below, describe what you observe and why it happened.   \n",
    "$Hint$ :  why `.isnull()` didn't work?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NA_dict = [{ 'id': 'A', 'missing_example': np.nan },\n",
    "           { 'id': 'B'                    },\n",
    "           { 'id': 'C', 'missing_example': 'NaN'  },\n",
    "           { 'id': 'D', 'missing_example': 'None' },\n",
    "           { 'id': 'E', 'missing_example':  None  },\n",
    "           { 'id': 'F', 'missing_example': ''     }]\n",
    "\n",
    "NA_df = pd.DataFrame(NA_dict, columns = ['id','missing_example'])\n",
    "NA_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NA_df['missing_example'].isnull()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### My Answer ###\n",
    "The value in 2 and 3 are 'NaN', 'None'. pd.isnull() will see them as a 'string'. Since they are 'string' types, they are not 'null' anymore. \\\n",
    "Also, the value in 5 is a empty string, its also a string so pd.isnull() will take it as a 'string' type instead of python 'None' type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### >>> Exercise 6 (take home):\n",
    "Notice any changes to the `X` dataframe? What are they? Report every change you noticed as compared to the previous state of `X`. Feel free to query and look more closely at the dataframe for these changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X_sample = X.sample(n=1000) #random state\n",
    "print(len(X_sample))\n",
    "X_sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### My Answer ###\n",
    "The size of X_sample is 1000, smaller then original X. And also the order of X_sample is disrupted due to the random sample process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### >>> **Exercise 8 (take home):** \n",
    "We can also do a side-by-side comparison of the distribution between the two datasets, but maybe you can try that as an excerise. Below we show you an snapshot of the type of chart we are looking for. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt txt](https://i.imgur.com/9eO431H.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "xticks = np.array([0, 1, 2, 3])\n",
    "bar_width = 0.2\n",
    "sample_data = X_sample.category_name.value_counts()\n",
    "original_data = X.category_name.value_counts()\n",
    "\n",
    "pd.concat([original_data, sample_data], axis=1).plot(kind = 'bar',\n",
    "                                               title = 'Category distribution',\n",
    "                                               ylim = [0, 650], \n",
    "                                               width = 0.4,\n",
    "                                               rot = 0, fontsize = 12, figsize = (8,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **>>> Exercise 10 (take home):**\n",
    "We said that the `1` at the beginning of the fifth record represents the `00` term. Notice that there is another 1 in the same record. Can you provide code that can verify what word this 1 represents from the vocabulary. Try to do this as efficient as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "X['unigrams'] = X['text'].apply(lambda x: dmh.tokenize_text(x))\n",
    "\n",
    "\n",
    "\n",
    "count_vect = CountVectorizer()\n",
    "X_counts = count_vect.fit_transform(X.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_counts[0:5, 0:100].toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### My Answer ###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_array = np.array(count_vect.get_feature_names()[0:100])\n",
    "# transform a array like [1, 0, 1, 0, 0 ...] to [True, False, True, False, False ...]\n",
    "# and this kind of Boolean array can be used by a numpy array as a mask array\n",
    "mask_array = [i == 1 for i in np.ravel(X_counts[4, 0:100].toarray())]\n",
    "print(name_array[mask_array])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we know the `1`s in the word vector means. The first `1` means `00` and the second `1` means `01`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **>>> Exercise 11 (take home):** \n",
    "From the chart above, we can see how sparse the term-document matrix is; i.e., there is only one terms with frequency of `1` in the subselection of the matrix. By the way, you may have noticed that we only selected 20 articles and 20 terms to plot the histrogram. As an excersise you can try to modify the code above to plot the entire term-document matrix or just a sample of it. How would you do this efficiently? Remember there is a lot of words in the vocab. Report below what methods you would use to get a nice and useful visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# first twenty features only\n",
    "plot_x = [\"term_\"+str(i) for i in count_vect.get_feature_names()]\n",
    "# obtain document index\n",
    "plot_y = [\"doc_\"+ str(i) for i in list(X.index)]\n",
    "plot_z = X_counts.toarray()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_todraw = pd.DataFrame(plot_z, columns = plot_x, index = X.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_todraw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(figsize=(9, 7))\n",
    "ax = sns.heatmap(df_todraw.sample(1),\n",
    "                 cmap=\"PuRd\",\n",
    "                 vmin=0, vmax=1, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### >>> Exercise 12 (take home):\n",
    "Please try to reduce the dimension to 3, and plot the result use 3-D plot. Use at least 3 different angle (camera position) to check your result and describe what you found.\n",
    "\n",
    "$Hint$: you can refer to Axes3D in the documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "X_reduced = PCA(n_components = 2).fit_transform(X_counts.toarray())\n",
    "col = ['coral', 'blue', 'black', 'm']\n",
    "\n",
    "# plot\n",
    "fig = plt.figure(figsize = (25,10))\n",
    "ax = fig.subplots()\n",
    "\n",
    "for c, category in zip(col, categories):\n",
    "    xs = X_reduced[X['category_name'] == category].T[0]\n",
    "    ys = X_reduced[X['category_name'] == category].T[1]\n",
    "   \n",
    "    ax.scatter(xs, ys, c = c, marker='o')\n",
    "\n",
    "ax.grid(color='gray', linestyle=':', linewidth=2, alpha=0.2)\n",
    "ax.set_xlabel('\\nX Label')\n",
    "ax.set_ylabel('\\nY Label')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import axes3d, Axes3D\n",
    "\n",
    "X_reduced = PCA(n_components = 3).fit_transform(X_counts.toarray())\n",
    "col = ['coral', 'blue', 'black', 'm']\n",
    "\n",
    "# plot\n",
    "fig = plt.figure()\n",
    "ax = Axes3D(fig)\n",
    "\n",
    "\n",
    "for c, category in zip(col, categories):\n",
    "    xs = X_reduced[X['category_name'] == category].T[0]\n",
    "    ys = X_reduced[X['category_name'] == category].T[1]\n",
    "    zs = X_reduced[X['category_name'] == category].T[2]\n",
    "   \n",
    "    ax.scatter(xs, ys, c = c, marker='o')\n",
    "\n",
    "ax.grid(color='gray', linestyle=':', linewidth=2, alpha=0.2)\n",
    "ax.set_xlabel('\\nX Label')\n",
    "ax.set_ylabel('\\nY Label')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### >>> **Exercise 13 (take home):**\n",
    "If you want a nicer interactive visualization here, I would encourage you try to install and use plotly to achieve this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import progressbar\n",
    "# note this takes time to compute. You may want to reduce the amount of terms you want to compute frequencies for\n",
    "term_frequencies = []\n",
    "for j in progressbar.progressbar(range(0,X_counts.shape[1])):\n",
    "    term_frequencies.append(sum(X_counts[:,j].toarray()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "term_frequencies = np.asarray(X_counts.sum(axis=0))[0]\n",
    "\n",
    "#plt.subplots(figsize=(100, 10))\n",
    "#g = sns.barplot(x=count_vect.get_feature_names()[:300], \n",
    "#            y=term_frequencies[:300])\n",
    "#g.set_xticklabels(count_vect.get_feature_names()[:300], rotation = 90);\n",
    "\n",
    "import plotly.express as px\n",
    "data = pd.DataFrame({'frequency': term_frequencies, 'term': count_vect.get_feature_names()})\n",
    "fig = px.bar(data[1000:2300], x='term', y='frequency')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### >>> **Exercise 14 (take home):** \n",
    "The chart above contains all the vocabulary, and it's computationally intensive to both compute and visualize. Can you efficiently reduce the number of terms you want to visualize as an exercise. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import words\n",
    "len(words.words())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cache = words.words()\n",
    "\n",
    "def find_in_corpus(t):\n",
    "    index, item = t\n",
    "    # for a better performance, drop the terms that frequency less then 1\n",
    "    if(item.frequency <= 50):\n",
    "        return False\n",
    "    # filter out the terms not in dictionary\n",
    "    return item.term in cache\n",
    "\n",
    "data['in_dictionary'] =[find_in_corpus(t) for t in progressbar.progressbar(data.iterrows())]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### >>> **Exercise 15 (take home):** \n",
    "Additionally, you can attempt to sort the terms on the `x-axis` by frequency instead of in alphabetical order. This way the visualization is more meaninfgul and you will be able to observe the so called [long tail](https://en.wikipedia.org/wiki/Long_tail) (get familiar with this term since it will appear a lot in data mining and other statistics courses). see picture below\n",
    "\n",
    "![alt txt](https://upload.wikimedia.org/wikipedia/commons/thumb/8/8a/Long_tail.svg/1000px-Long_tail.svg.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sorted_data = data.sort_values(by='frequency', ascending=False)\n",
    "fig = px.bar(sorted_data[sorted_data['in_dictionary']], x='term', y='frequency', log_y=True)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math\n",
    "term_frequencies_log = [math.log(i) for i in term_frequencies]\n",
    "plt.subplots(figsize=(100, 10))\n",
    "g = sns.barplot(x=count_vect.get_feature_names()[:300],\n",
    "                y=term_frequencies_log[:300])\n",
    "g.set_xticklabels(count_vect.get_feature_names()[:300], rotation = 90);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### >>> **Exercise 16 (take home):**\n",
    "Try to generate the binarization using the `category_name` column instead. Does it work?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing, metrics, decomposition, pipeline, dummy\n",
    "mlb = preprocessing.LabelBinarizer()\n",
    "mlb.fit(X.category_name)\n",
    "print(mlb.classes_)\n",
    "X['bin_category'] = mlb.transform(X['category_name']).tolist()\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### My Answer ###\n",
    "It worked. But be careful when doing the fit process of the binarizer. \\\n",
    "The fit process shold use `X.category_name` as well. \\\n",
    "Like: \\\n",
    "`mlb.fit(X.category_name)` \\\n",
    "But not \\\n",
    "`mlb.fit(X.category)` \\\n",
    "This will have problem when doing `mlb.transform(X['category_name'])`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. The New Dataset\n",
    "\n",
    "### Tasks to Do\n",
    "1. [Data Source](#1.-Data-Source)\n",
    "2. [Data Preparation](#2.-Data-Preparation)\n",
    "3. [Data Transformation](#3.-Data-Transformation) \\\n",
    "    3.1 Converting Dictionary into Pandas dataframe \\\n",
    "    3.2 Familiarizing yourself with the Data\n",
    "4. [Data Mining using Pandas](#4.-Data-Mining-using-Pandas) \\\n",
    "    4.1 [Dealing with Missing Values](#4.1-Dealing-with-Missing-Values) \\\n",
    "    4.2 [Dealing with Duplicate Data](#4.2-Dealing-with-Duplicate-Data)\n",
    "5. [Data Preprocessing](#5.-Data-Preprocessing) \\\n",
    "    5.1 [Sampling](#5.1-Sampling) \\\n",
    "    5.2 [Feature Creation](#5.2-Feature-Creation) \\\n",
    "    5.3 [Feature Subset Selection](#5.3-Feature-Subset-Selection) \\\n",
    "    5.4 [Dimensionality Reduction](#5.4-Dimensionality-Reduction) \\\n",
    "    5.5 [Atrribute Transformation / Aggregation](#5.5-Atrribute-Transformation-/-Aggregation) \\\n",
    "    5.6 [Discretization and Binarization](#5.6-Discretization-and-Binarization)\n",
    "6. [Data Exploration](#6.-Data-Exploration)\n",
    "7. Conclusion\n",
    "8. References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Data Source\n",
    "The new dataset is about a set of sentence labelled with `positive` or `negative` __sentiment__. \\\n",
    "There are three files I downloaded contain the data in the `./data/` folder: \n",
    "1. amazon_cells_labelled.txt\n",
    "2. imdb_labelled.txt\n",
    "3. yelp_labelled.txt\n",
    "\n",
    "So, let's start to prepare our data.\n",
    "### 2. Data Preparation\n",
    "Load the data using ```pd.read_table()``` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries:\n",
    "import pandas as pd\n",
    "from helpers import data_mining_helpers as dmh\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "import progressbar as pgbar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "amazon = pd.read_table('./data/amazon_cells_labelled.txt', sep='[\\t\\r]', names=['sentence', 'label'])\n",
    "imdb = pd.read_table('./data/imdb_labelled.txt', sep='[\\r\\t]', names=['sentence', 'label'])\n",
    "yelp = pd.read_table('./data/yelp_labelled.txt', sep='[\\r\\t]', names=['sentence', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amazon.loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amazon.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "yelp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Data Transformation\n",
    "Since we already use the pandas `DataFrame` to read the data, this step we just combine the datasets all together, and skip `3.1` and `3.2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the 'from' column to tag whhich dataset this record come from\n",
    "amazon['source'] = 'amazon'\n",
    "imdb['source'] = 'imdb'\n",
    "yelp['source'] = 'yelp'\n",
    "\n",
    "X = pd.concat([amazon, imdb, yelp], axis=0, ignore_index=True)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking data are combined correctly\n",
    "print(\"X's Length: %d\" % len(X))\n",
    "for name, item in zip(['amazon', 'imdb', 'yelp'], [amazon, imdb, yelp]):\n",
    "    print(\"%6s's length: %4d, number of record come from %6s in X: %4d\" % (name, len(item), name, sum(X['source'] == name)) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We got totally 3000 records above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Data Mining using Pandas\n",
    "### 4.1 Dealing with Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# checking missing values\n",
    "X.isnull().apply(lambda x: dmh.check_missing_values(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems that there are no missing value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Dealing with Duplicate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking duplicated data\n",
    "sum(X.duplicated())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X[X.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.drop_duplicates(keep='last', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# checking duplicated data again\n",
    "sum(X.duplicated())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking data are combined correctly\n",
    "print(\"X's Length: %d\" % len(X))\n",
    "for name, item in zip(['amazon', 'imdb', 'yelp'], [amazon, imdb, yelp]):\n",
    "    print(\"%6s's length: %4d, number of record come from %6s in X: %4d\" % (name, len(item), name, sum(X['source'] == name)) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems dealed!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Data Preprocessing\n",
    "### 5.1 Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.source.value_counts().index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sample = X.sample(1000)\n",
    "\n",
    "x = np.array([0, 1, 2])\n",
    "bar_width = 0.2\n",
    "plt.title('Category Distribution')\n",
    "plt.xticks(x, labels=X.source.value_counts().index)\n",
    "plt.bar(x-bar_width/2, X.source.value_counts(), width=bar_width)\n",
    "plt.bar(x+bar_width/2, X_sample.source.value_counts(), width=bar_width)\n",
    "plt.ylim([0, 1050])\n",
    "plt.legend(['X', 'X sample'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Feature Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes a like a minute or two to process\n",
    "X['unigrams'] = X['sentence'].apply(lambda x: dmh.tokenize_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[0:4][\"unigrams\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "list(X[0:1]['unigrams'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Feature subset selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def tok(text):\n",
    "\n",
    "    tokens = word_tokenize(text)\n",
    "    return tokens\n",
    "\n",
    "count_vect = CountVectorizer()\n",
    "X_counts = count_vect.fit_transform(X.sentence.values)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vect.get_feature_names()[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first twenty features only\n",
    "plot_x = [\"term_\"+str(i) for i in count_vect.get_feature_names()[100:500]]\n",
    "# obtain document index\n",
    "plot_y = [\"doc_\"+ str(i) for i in list(X.index)[100:500]]\n",
    "plot_z = X_counts[100:500, 100:500].toarray()\n",
    "\n",
    "df_todraw = pd.DataFrame(plot_z, columns = plot_x, index = plot_y)\n",
    "fig = px.imshow(df_todraw)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "X_reduced = PCA(n_components = 2).fit_transform(X_counts.toarray())\n",
    "print(X_reduced.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = ['black', 'blue']\n",
    "\n",
    "# plot\n",
    "fig = plt.figure(figsize = (25,10))\n",
    "ax = fig.subplots()\n",
    "\n",
    "for c, category in zip(col, [0, 1]):\n",
    "    xs = X_reduced[X['label'] == category].T[0]\n",
    "    ys = X_reduced[X['label'] == category].T[1]\n",
    "   \n",
    "    ax.scatter(xs, ys, c = c, marker='o')\n",
    "\n",
    "ax.grid(color='gray', linestyle=':', linewidth=2, alpha=0.2)\n",
    "ax.set_xlabel('\\nX Label')\n",
    "ax.set_ylabel('\\nY Label')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for 3d plot\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "pca_3 = PCA(n_components = 3).fit(X_counts.toarray())\n",
    "\n",
    "X_reduced_3 = pca_3.transform(X_counts.toarray())\n",
    "print(X_reduced_3.shape)\n",
    "\n",
    "# plot\n",
    "fig = plt.figure(figsize = (25,25))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "for label in zip([0, 1]):\n",
    "    xs = X_reduced_3[X['label'] == label].T[0]\n",
    "    ys = X_reduced_3[X['label'] == label].T[1]\n",
    "    zs = X_reduced_3[X['label'] == label].T[2]\n",
    "   \n",
    "   \n",
    "    ax.scatter(xs, ys, marker='o')\n",
    "\n",
    "ax.grid(color='gray', linestyle=':', linewidth=2, alpha=0.2)\n",
    "ax.set_xlabel('\\nX Label')\n",
    "ax.set_ylabel('\\nY Label')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5 Atrribute Transformation / Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import progressbar\n",
    "# note this takes time to compute. You may want to reduce the amount of terms you want to compute frequencies for\n",
    "term_frequencies = []\n",
    "for j in progressbar.progressbar(range(0,X_counts.shape[1])):\n",
    "    term_frequencies.append(sum(np.ravel(X_counts[:,j].toarray())))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(term_frequencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(figsize=(100, 10))\n",
    "g = sns.barplot(x=count_vect.get_feature_names()[:300], \n",
    "            y=term_frequencies[:300])\n",
    "g.set_xticklabels(count_vect.get_feature_names()[:300], rotation = 90);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "term_frequencies_log = [math.log(i) for i in term_frequencies]\n",
    "\n",
    "plt.subplots(figsize=(100, 10))\n",
    "g = sns.barplot(x=count_vect.get_feature_names()[:300],\n",
    "                y=term_frequencies_log[:300])\n",
    "g.set_xticklabels(count_vect.get_feature_names()[:300], rotation = 90);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.6 Discretization and Binarization\n",
    "Since the `label` in __the New Dataset__ is already binarized(positive sentences are labelled by `1` and negetive sentences are labelled by `0`). So we can just skip this step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### 6. Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We retrieve 2 sentences for a random record, here, indexed at 50 and 100\n",
    "document_to_transform_1 = []\n",
    "random_record_1 = X.iloc[50]\n",
    "random_record_1 = random_record_1['sentence']\n",
    "document_to_transform_1.append(random_record_1)\n",
    "\n",
    "document_to_transform_2 = []\n",
    "random_record_2 = X.iloc[100]\n",
    "random_record_2 = random_record_2['sentence']\n",
    "document_to_transform_2.append(random_record_2)\n",
    "\n",
    "document_to_transform_3 = []\n",
    "random_record_3 = X.iloc[150]\n",
    "random_record_3 = random_record_3['sentence']\n",
    "document_to_transform_3.append(random_record_3)\n",
    "print(document_to_transform_1)\n",
    "print(document_to_transform_2)\n",
    "print(document_to_transform_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import binarize\n",
    "\n",
    "# Transform sentence with Vectorizers\n",
    "document_vector_count_1 = count_vect.transform(document_to_transform_1)\n",
    "document_vector_count_2 = count_vect.transform(document_to_transform_2)\n",
    "document_vector_count_3 = count_vect.transform(document_to_transform_3)\n",
    "\n",
    "# Binarize vecors to simplify: 0 for abscence, 1 for prescence\n",
    "document_vector_count_1_bin = binarize(document_vector_count_1)\n",
    "document_vector_count_2_bin = binarize(document_vector_count_2)\n",
    "document_vector_count_3_bin = binarize(document_vector_count_3)\n",
    "\n",
    "# print\n",
    "print(\"Let's take a look at the count vectors:\")\n",
    "print(document_vector_count_1.todense())\n",
    "print(document_vector_count_2.todense())\n",
    "print(document_vector_count_3.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Calculate Cosine Similarity\n",
    "cos_sim_count_1_2 = cosine_similarity(document_vector_count_1, document_vector_count_2, dense_output=True)\n",
    "cos_sim_count_1_3 = cosine_similarity(document_vector_count_1, document_vector_count_3, dense_output=True)\n",
    "cos_sim_count_1_1 = cosine_similarity(document_vector_count_1, document_vector_count_1, dense_output=True)\n",
    "cos_sim_count_2_2 = cosine_similarity(document_vector_count_2, document_vector_count_2, dense_output=True)\n",
    "\n",
    "# Print \n",
    "print(\"Cosine Similarity using count bw 1 and 2: %(x)f\" %{\"x\":cos_sim_count_1_2})\n",
    "print(\"Cosine Similarity using count bw 1 and 3: %(x)f\" %{\"x\":cos_sim_count_1_3})\n",
    "print(\"Cosine Similarity using count bw 1 and 1: %(x)f\" %{\"x\":cos_sim_count_1_1})\n",
    "print(\"Cosine Similarity using count bw 2 and 2: %(x)f\" %{\"x\":cos_sim_count_2_2})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In above cell, the Similarity between 1, 2, 3 are all 0 since they are exactly totally different sentences. So the outcome is acceptable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Third: please attempt the following tasks on **the new dataset**. __This part is worth 30% of your grade.__\n",
    "    - Generate meaningful **new data visualizations**. Refer to online resources and the Data Mining textbook for inspiration and ideas. \n",
    "    - Generate **TF-IDF features** from the tokens of each text. This will generating a document matrix, however, the weights will be computed differently (using the TF-IDF value of each word per document as opposed to the word frequency). Refer to this Sciki-learn [guide](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html) .\n",
    "    - Implement a simple **Naive Bayes classifier** that automatically classifies the records into their categories. Use both the TF-IDF features and word frequency features to build two seperate classifiers. Comment on the differences.  Refer to this [article](https://hub.packtpub.com/implementing-3-naive-bayes-classifiers-in-scikit-learn/).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Classify the Dataset\n",
    "1. [Visualizations](#1.-Visualizations)\n",
    "2. [TF-IDF Features](#2.-TF-IDF-Features)\n",
    "3. [Naive Bayes Classification](#3.-Naive-Bayes-Classification) \\\n",
    "    3.1 [Using TF-IDF](#3.1-Using-TF-IDF) \\\n",
    "    3.2 [Using Word Frequency Features](#3.2-Using-Word-Frequency-Features) \\\n",
    "    3.3 [Simple Discussion](#3.3-Simple-Discussion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Visualizations\n",
    "1. 1 Using a frequency bar plot, but sort the terms using frequency first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_frequency = pd.DataFrame({'frequency': term_frequencies, 'term': count_vect.get_feature_names()})\n",
    "\n",
    "df_frequency_sorted = df_frequency.sort_values(by='frequency', ascending=False)\n",
    "fig = px.bar(df_frequency_sorted[:300], x='term', y='frequency', log_y=True)\n",
    "fig.show()\n",
    "fig = px.bar(df_frequency_sorted[300:600], x='term', y='frequency', log_y=True)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But actually most of the first 300 items are the `stop words`, like _the, it, is_ …and so on. \\\n",
    "So I try to plot the frequency plot __without__ `stop words`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vect_sw = CountVectorizer(stop_words='english')\n",
    "X_counts_sw = count_vect_sw.fit_transform(X.sentence.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import progressbar\n",
    "# note this takes time to compute. You may want to reduce the amount of terms you want to compute frequencies for\n",
    "term_frequencies_sw = []\n",
    "for j in progressbar.progressbar(range(0,X_counts_sw.shape[1])):\n",
    "    term_frequencies_sw.append(sum(np.ravel(X_counts_sw[:,j].toarray())))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_frequency = pd.DataFrame({'frequency': term_frequencies_sw, 'term': count_vect_sw.get_feature_names()})\n",
    "\n",
    "df_frequency_sorted = df_frequency.sort_values(by='frequency', ascending=False)\n",
    "fig = px.bar(df_frequency_sorted[:300], x='term', y='frequency', log_y=True)\n",
    "fig.show()\n",
    "fig = px.bar(df_frequency_sorted[300:600], x='term', y='frequency', log_y=True)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `explained_variance_` attribute of `pca_3` can represent the importance of each component. \\\n",
    "So we can visualize the importance of the components via a bar plot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_3 = PCA(n_components = 3).fit(X_counts.toarray())\n",
    "\n",
    "X_reduced_3 = pca_3.transform(X_counts.toarray())\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.bar(np.arange(3), pca_3.explained_variance_)\n",
    "plt.xticks(np.arange(3))\n",
    "plt.xlabel('components')\n",
    "plt.ylabel('importance')\n",
    "plt.title('The importance of the components')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 20\n",
    "pca_n = PCA(n_components=n).fit(X_counts.toarray())\n",
    "\n",
    "X_reduced_n = pca_n.transform(X_counts.toarray())\n",
    "\n",
    "plt.bar(np.arange(n), pca_n.explained_variance_)\n",
    "plt.xticks(np.arange(n))\n",
    "plt.xlabel('components')\n",
    "plt.ylabel('importance')\n",
    "plt.title('The importance of the components')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. TF-IDF Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_tfidf = vectorizer.fit_transform(X.sentence.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import progressbar\n",
    "# note this takes time to compute. You may want to reduce the amount of terms you want to compute frequencies for\n",
    "term_tfidf = []\n",
    "for j in progressbar.progressbar(range(0,X_tfidf.shape[1])):\n",
    "    term_tfidf.append(sum(np.ravel(X_tfidf[:,j].toarray())))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$tf_{i, j} = \\frac{n_{i, j}}{\\sum_{k}n_{k, j}}$$\n",
    "$n_{i, j}$ is for the frequency of the term $t_{i}$ in document $d_{j}$. \\\n",
    "and $\\sum_{k}n_{k, j}$ means the number of tokens in $d_j$, which sums all $n_{i,j}$ together for $i \\in [0, k]$ \\\n",
    "\\\n",
    "The meaning of $\\sum_j tfidf_{i, j} = \\sum_j tf_{i, j}idf_{i}$ for term $t_j$ is ?\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\sum_j tfidf_{i, j} &= \\sum_j tf_{i, j}idf_{i}  \\\\\n",
    "&= idf_{i}\\sum_j tf_{i, j}\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "idf_mapping = pd.DataFrame({'term': vectorizer.get_feature_names(), 'idf': vectorizer.idf_ })\n",
    "\n",
    "idf_sorted = idf_mapping.sort_values(by='idf', ascending=False)\n",
    "fig = px.histogram(idf_mapping, x=\"idf\", nbins=10)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Try to plot a PCA using n_components=2\n",
    "from sklearn.decomposition import PCA\n",
    "X_tfidf_reduced = PCA(n_components = 2).fit_transform(X_tfidf.toarray())\n",
    "print(X_tfidf_reduced.shape)\n",
    "\n",
    "col = ['black', 'blue']\n",
    "\n",
    "# plot\n",
    "fig = plt.figure(figsize = (25,10))\n",
    "ax = fig.subplots()\n",
    "\n",
    "for c, category in zip(col, [0, 1]):\n",
    "    xs = X_tfidf_reduced[X['label'] == category].T[0]\n",
    "    ys = X_tfidf_reduced[X['label'] == category].T[1]\n",
    "   \n",
    "    ax.scatter(xs, ys, c = c, marker='o')\n",
    "\n",
    "ax.grid(color='gray', linestyle=':', linewidth=2, alpha=0.2)\n",
    "ax.set_xlabel('\\nX Label')\n",
    "ax.set_ylabel('\\nY Label')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.Naive Bayes Classification\n",
    "#### 3.1 Using TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, plot_roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_df = pd.DataFrame(columns=['dataset', 'classify_method', 'accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_tfidf_train, X_tfidf_test, y_train, y_test = train_test_split(X_tfidf, X['label'], test_size=0.3, random_state=0)\n",
    "\n",
    "bnb_tfidf = BernoulliNB(binarize=0.0)\n",
    "bnb_tfidf.fit(X_tfidf_train, y_train)\n",
    "y_tfidf_train_pred = bnb.predict(X_tfidf_train)\n",
    "y_tfidf_test_pred = bnb.predict(X_tfidf_test)\n",
    "acc_df = acc_df.append( {\n",
    "                'dataset': 'tfidf', \n",
    "                'classify_method': 'bnb',\n",
    "                'accuracy': accuracy_score(y_tfidf_test_pred, y_test)\n",
    "               }, ignore_index=True)\n",
    "\n",
    "\n",
    "mnb_tfidf = MultinomialNB()\n",
    "mnb_tfidf.fit(X_tfidf_train, y_train)\n",
    "y_tfidf_train_pred = mnb.predict(X_tfidf_train)\n",
    "y_tfidf_test_pred = mnb.predict(X_tfidf_test)\n",
    "acc_df = acc_df.append( {\n",
    "                'dataset': 'tfidf', \n",
    "                'classify_method': 'mnb',\n",
    "                'accuracy': accuracy_score(y_tfidf_test_pred, y_test)\n",
    "               }, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Using Word Frequency Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_counts_train, X_counts_test, y_train, y_test = train_test_split(X_counts, X['label'], test_size=0.3, random_state=0)\n",
    "\n",
    "bnb_counts = BernoulliNB(binarize=0.0)\n",
    "bnb_counts.fit(X_counts_train, y_train)\n",
    "y_counts_train_pred = bnb.predict(X_counts_train)\n",
    "y_counts_test_pred = bnb.predict(X_counts_test)\n",
    "acc_df = acc_df.append( {\n",
    "                'dataset': 'counts', \n",
    "                'classify_method': 'bnb',\n",
    "                'accuracy': accuracy_score(y_counts_test_pred, y_test)\n",
    "               }, ignore_index=True)\n",
    "\n",
    "\n",
    "mnb_counts = MultinomialNB()\n",
    "mnb_counts.fit(X_counts_train, y_train)\n",
    "y_counts_train_pred = mnb.predict(X_counts_train)\n",
    "y_counts_test_pred = mnb.predict(X_counts_test)\n",
    "acc_df = acc_df.append( {\n",
    "                'dataset': 'counts', \n",
    "                'classify_method': 'mnb',\n",
    "                'accuracy': accuracy_score(y_counts_test_pred, y_test)\n",
    "               }, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we got a accuracy table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "acc_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3 Simple Discussion\n",
    "First, let me draw some comparation graph to get a more visualized outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "fig = px.bar(acc_df, x='dataset', y='accuracy', barmode='group', color='classify_method', range_y=[0.8, 0.825],\n",
    "            title='Accuracy Comparation between Dataset and Classify Method')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Bernoulli Naive Bayesian Classifier, the accuracy of TF-IDF(tfidf) and Frequency(counts) are same. \\\n",
    "Since Bernoulli treat numbers as binary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.plot(np.arange(5155), np.ravel(X_counts[0].toarray()))\n",
    "plt.plot(np.arange(5155), np.ravel(X_tfidf[0].toarray()))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The graph above shows two vector on the first record of our data -- the first sentence in amazon_cells_labelled.txt -- \"So there is no way for me to plug it in here in the US unless I go by a converter.\" \\\n",
    "Let's look at the terms and statistics numbers more clearly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "temp = idf_mapping[np.ravel(X_tfidf[0].toarray())> 0]\n",
    "X_0_feature = pd.DataFrame({\n",
    "    'term': temp.term,\n",
    "    'idf': temp.idf,\n",
    "    'frequency': df_frequency.frequency[np.ravel(X_tfidf[0].toarray())> 0],\n",
    "    'counts': np.ravel(X_counts[0].toarray())[np.ravel(X_counts[0].toarray())> 0],\n",
    "    'tfidf': np.ravel(X_tfidf[0].toarray())[np.ravel(X_tfidf[0].toarray())> 0]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_0_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mapping the terms and numbers all together. The vector is very sparse that the value not in the table are all zero. \\\n",
    "And a Bernoulli will treat all positive value above as 1, so TF-IDF vector and counts vector in Bernoulli are the same! \\\n",
    "This is how Bernoulli Naive Bayesian Classifier has same accuracy on two different features. \\\n",
    "But for Multinomial Naive Bayesian Classifier, this classifier treat numbers in multinomial distribution. Since the treatment is no longer 0 or 1, I expected the outcome of TF-IDF will better than simple Frequency based CountVector. \\\n",
    "But the truth is not. CountVector even better than TF-IDF, although the difference of accuracy is less than 0.01. \\\n",
    "So I try to use a cross validation to see the average performance of two dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "\n",
    "classifier = MultinomialNB()\n",
    "cv=KFold(n_splits=12, shuffle=True, random_state=0)\n",
    "\n",
    "acc_counts = cross_val_score(classifier, X_counts.toarray(), X['label'], cv=cv)\n",
    "acc_tfidf = cross_val_score(classifier, X_tfidf.toarray(), X['label'], cv=cv)\n",
    "plt.boxplot([acc_counts, acc_tfidf])\n",
    "plt.xticks([1, 2], ['counts', 'tfidf'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And also plot a __ROC Curve__ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "bnb_tfidf_disp = plot_roc_curve(bnb_tfidf, X_tfidf_test, y_test)\n",
    "plot_roc_curve(mnb_tfidf, X_tfidf_test, y_test, ax=bnb_tfidf_disp.ax_)\n",
    "bnb_tfidf_disp.figure_.suptitle(\"ROC curve comparison of TF-IDF Features\")\n",
    "bnb_counts_disp = plot_roc_curve(bnb_counts, X_counts_test, y_test)\n",
    "plot_roc_curve(mnb_counts, X_counts_test, y_test, ax=bnb_counts_disp.ax_)\n",
    "bnb_counts_disp.figure_.suptitle(\"ROC curve comparison of Frequency Features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "cos_sim = cosine_similarity(X_counts, X_tfidf, dense_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = px.imshow(cos_sim)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "fig = go.Figure(data=[\n",
    "    go.Bar(name=n, x=X_0_feature['term'], y=X_0_feature[n]) for n in ['counts', 'tfidf']\n",
    "])\n",
    "# Change the bar mode\n",
    "fig.update_layout(barmode='group')\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
